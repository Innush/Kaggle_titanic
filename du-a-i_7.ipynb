{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\n","df_test = pd.read_csv('/kaggle/input/titanic/test.csv')\n","df_train.shape"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_train.head(10)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["#Find columns with Nans in them\n","print(\"Columns with missing values: \")\n","print(df_train.columns[df_train.isnull().any()].tolist())"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(df_train.isnull().sum())"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["There are 3 ways to handle null values\n","\n","1.Remove NaN rows\n","  2.Set NaN to hard coded value\n","  3.Impute NaN values based on other rows  \n","  here, for Embarked we did 1"]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(\"Before dropping - \" + str(len(df)) + \" rows\")\n","df_train = df_train[~df_train['Embarked'].isna()]\n","print(\"After dropping - \" + str(len(df)) + \" rows\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["For Cabin we will do 3. Impute NaN values based on other rows."]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_train['Cabin'].value_counts()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["most_frequent_cabin = df_train['Cabin'].value_counts().idxmax()\n","print(\"Most Frequent Cabin = \" + most_frequent_cabin)\n","print(\"NA count before fill = \" + str(len(df_train[df_train['Cabin'].isna()])))\n","df_train['Cabin'] = df_train['Cabin'].fillna(most_frequent_cabin)\n","print(\"NA count after fill = \" + str(len(df_train[df_train['Cabin'].isna()])))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Since Age is numerical, let us impute its value by filling it with the mean age of passengers on the ship."]},{"metadata":{"trusted":true},"cell_type":"code","source":["mean_age = df_train['Age'].mean()\n","print(\"Mean age of passengers = \" + str(mean_age))\n","print(\"NA count before fill = \" + str(len(df_train[df_train['Age'].isna()])))\n","df_train['Age'] = df_train['Age'].fillna(mean_age)\n","print(\"NA count after fill = \" + str(len(df_train[df_train['Age'].isna()])))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["#statistical distribution\n","df_train.describe()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["hist = df_train.hist(figsize=(10,10),layout=(3,4))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["sns.pairplot(df_train)\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Correlation between data"]},{"metadata":{"trusted":true},"cell_type":"code","source":["\n","corr=df_train.corr()\n","\n","corr.style.background_gradient(cmap='coolwarm')\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Correaltions observed in Titanic:\n","\n","Pclass and Fare\n","Age and Parch\n","Age and SibSp\n","Age and Pclass\n","Pclass and Survived"]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_train['RelativeCount'] = df_train['SibSp'] + df_train['Parch']\n","df_train['RelativeCount'].describe()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["corr=df_train.corr()\n","\n","corr.style.background_gradient(cmap='coolwarm')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_train.head(100)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["hist = df_train.hist(figsize=(10,10),column='RelativeCount')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["**Was a passenger travelling alone?**\n","\n","numpy.where(): Return elements chosen from x or y depending on condition.\n","https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html"]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_train['TravelAlone'] = np.where(df_train['SibSp']+df_train['Parch']>0, \"No\", \"Yes\")\n","df_train.head()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_train['TravelAlone'].value_counts()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["See types of plots_documentations pandas"]},{"metadata":{"trusted":true},"cell_type":"code","source":["#Since its too much data to visualize and understand, lets bucket the age as below\n","#feature engineering FTW!\n","def bucket_age(age):\n","  if age < 15:\n","    return \"<15\"\n","  if age >= 15 and age < 30:\n","    return \"15-30\"\n","  if age >=30 and age < 45:\n","    return \"30-45\"\n","  if age>=45 and age < 60:\n","    return \"45-60\"\n","  return \">60\"\n","\n","df_train['AgeBucket'] = df_train['Age'].apply(bucket_age)\n","\n","#Visualize this with a pie chart\n","pie = df_train['AgeBucket'].value_counts().plot(kind=\"pie\",title='AgeBucket Distribution',legend=True,autopct='%1.1f%%')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Box Plots\n","A boxplot is a standardized way of displaying the distribution of data based on a five number summary (“minimum”, first quartile (Q1), median, third quartile (Q3), and “maximum”). It can tell you about your outliers and what their values are. It can also tell you if your data is symmetrical, how tightly your data is grouped, and if and how your data is skewed.\n","\n","\n","Reference\n","\n","https://www.khanacademy.org/math/statistics-probability/summarizing-quantitative-data/box-whisker-plots/a/box-plot-review\n","https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51"]},{"metadata":{"trusted":true},"cell_type":"code","source":["##### Box Plots\n","\n","#A boxplot is a standardized way of displaying the distribution of data based on a five number summary (“minimum”, first quartile (Q1), median, third quartile (Q3), and “maximum”). It can tell you about your outliers and what their values are. It can also tell you if your data is symmetrical, how tightly your data is grouped, and if and how your data is skewed.\n","\n","#![alt text](https://miro.medium.com/max/18000/1*2c21SkzJMf3frPXPAR_gZA.png)\n","\n","#Reference \n","#- https://www.khanacademy.org/math/statistics-probability/summarizing-quantitative-data/box-whisker-plots/a/box-plot-review\n","#- https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["**Sex and Fare Relationship**"]},{"metadata":{"trusted":true},"cell_type":"code","source":["sns.catplot(x=\"Sex\", y=\"Fare\", kind=\"box\", data=df_train)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["How does the Pclass relate to the Survival rate?"]},{"metadata":{"trusted":true},"cell_type":"code","source":["#Lets start off with a bar plot of the Pclass distribution\n","pie = df_train['Pclass'].value_counts().plot(kind=\"pie\",title='PClass Distribution',legend=True,autopct='%1.1f%%')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["sns.catplot(x=\"RelativeCount\", y=\"AgeBucket\", kind=\"box\", data=df_train)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["sns.catplot(x=\"RelativeCount\", y=\"Age\", kind=\"box\", data=df_train)\n"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_train.head(5)\n"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_train.head(10)\n"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# NAME\n","\n","# Name Length\n","# I Can't really Explain why but name length has a clear pattern and seems to significantly improve the\n","# result and hence I am obliged to use it in my Code\n","df_train['Name_Length'] = df_train['Name'].apply(lambda x : len(x))\n","df_train['Name_Length'] = ((df_train.Name_Length)/15).astype(np.int64)+1\n","print(df_train[['Name_Length','Survived']].groupby(['Name_Length'], as_index = False).mean())\n","plt.subplots(figsize=(15, 6))\n","sns.barplot(data=df_train,x='Name_Length',y='Survived')\n"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# You may now think that Name is a useless column but Name contains somethings very important,'Titles'\n","# If You observe closely you will notice that all names have a Title, example : 'MR','Mrs','Cpt',etc\n","\n","# EXTRACTING TITLE FORM NAME\n","title = df_train.Name.values\n","import re\n","for i in range(len(title)):\n","    r = re.search(', ([A-Za-z ]*)',title[i])\n","    title[i] = r.group(1)\n","df_train.loc[:,'Name'] = title \n","plt.subplots(figsize=(15, 6))\n","sns.barplot(data=df_train,x='Name',y='Survived')\n","# Hence from the figure below show that it may play an important role in the decision making process"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Now We have completed Phase 1 of the Code that is Preprocesing Infromation\n","# the 2nd Phase of the code is to encode the data and and dropiing unwanted columns\n","\n","# Encoding String values to Numbers\n","from sklearn.preprocessing import LabelEncoder\n","\n","#SEX\n","lb_Sex = LabelEncoder()\n","df_train['Sex'] = lb_Sex.fit_transform(df_train.Sex)\n","\n"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["\n","#TITLE\n","lb_Title = LabelEncoder()\n","df_train['Name'] = lb_Title.fit_transform(df_train.Name)\n","\n","# DROPPING THE EXTRA COLUMNS\n","df_train.drop(labels=['SibSp','Parch','Ticket','Fare','Age','PassengerId','Cabin',],axis=1,inplace=True)\n","\n","\n"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_train.head()\n"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_train.drop(labels=['Embarked'],axis=1,inplace=True)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_train.head()\n"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["#RETREIVING THE TEST AND THE TRAIN SETS\n","df_test = df_train[df_train.Survived.isnull()]\n","df_train = df_train[df_train.Survived.notnull()]\n","\n","df_test = df_test.drop(['Survived'],axis=1)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["#DIVIDING THE DATA INTO Y_TRAIN AND X_TRAIN AND CONVERTING THEM INTO NP ARRAYS\n","y_train = df_train.loc[:,'Survived'].values\n","x_train =df_train.drop(['Survived'],axis=1).values\n","x_test = df_test.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Feature Scaling \n","from sklearn.preprocessing import MinMaxScaler\n","sc_x = MinMaxScaler((-1,1))\n","x_train  = sc_x.fit_transform(x_train)\n","x_test = sc_x.transform(x_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Confusion Matrix\n","from sklearn.metrics import confusion_matrix\n","dict_K = {}\n","dic = {}\n","\n","#Kfold Validation\n","def get_acc(Xtrain,Ytrain,model):\n","    from sklearn.model_selection import KFold\n","    acc = []\n","    k=KFold(n_splits=4)\n","    for train , test in k.split(Xtrain,y=Ytrain):\n","        x_train = Xtrain[train,:]\n","        y_train = Ytrain[train]\n","        x_test = Xtrain[test,:]\n","        y_test = Ytrain[test]\n","        model.fit(x_train,y_train)\n","        y_pred = model.predict(x_test)\n","        cm = confusion_matrix(y_true=y_test,y_pred=y_pred)\n","        acc.append((cm[1,1]+cm[0,0])/((cm[1,0]+cm[0,1]+cm[1,1]+cm[0,0])+1e-5))\n","    return acc"]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_train.head()"],"execution_count":null,"outputs":[]},{"source":["from sklearn.ensemble import RandomForestClassifier\n","classifier = RandomForestClassifier(n_estimators=25,criterion='entropy')\n","dict_K['Random_forest'] = get_acc(x_train,y_train,classifier)\n","classifier.fit(x_train, y_train)\n","y_pred = classifier.predict(x_test)"],"cell_type":"code","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Preparing the CSV For Submition\n","p = dataset_gd.PassengerId\n","p = pd.concat([p,pd.DataFrame(y_pred.astype(np.int64),columns=['Survived'])],axis=1)\n","p.to_csv('Tit_pred.csv',index=False)"]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.2-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}